1
00:00:00,000 --> 00:00:15,000
검색해서 구글 코랩에 들어갑니다.

2
00:00:15,100 --> 00:00:23,000
A100 GPU를 선택합니다.

3
00:00:23,100 --> 00:00:30,000
구글 코랩에 연결되고 있습니다.

4
00:00:30,100 --> 00:00:40,000
연결 목적은 GPU 이용입니다.

5
00:00:40,100 --> 00:00:50,000
사무실에 GPU가 없으니까요.

6
00:00:50,100 --> 00:01:30,000
파이썬 코드, 학습 자료 업로드

7
00:01:30,100 --> 00:02:20,000
RAG 라이브러리 설치

8
00:02:20,100 --> 00:02:30,000
ngrok 연결 준비

9
00:02:30,100 --> 00:02:55,000
ngrok 으로 코랩에서 챗봇 UI를 띄웁니다.

10
00:02:55,100 --> 00:03:10,000
ngrok 으로 챗봇 URL을 얻습니다.

11
00:03:10,100 --> 00:04:00,000
챗봇을 시작합니다.

12
00:04:00,100 --> 00:04:10,000
먼저 라마3 LLM을 VRAM에 로드합니다.

13
00:04:10,100 --> 00:04:20,000
10분 정도 소요됩니다.

14
00:04:20,100 --> 00:04:30,000
로딩이 끝나면 챗봇을 이용할 수 있습니다.

15
00:04:30,000 --> 00:04:40,000
계속 기다려야 합니다.

16
00:04:40,100 --> 00:04:50,000
12:55 로 건너뛰기 하셔도 됩니다.

17
00:04:50,100 --> 00:05:00,000
GPU가 없어서 구글 코랩을 이용합니다.

18
00:05:00,100 --> 00:05:10,000
사무실 PC의 CPU로는 8시간 만에 답변합니다.

19
00:05:10,100 --> 00:05:20,000
8시간 만에 답변 하는 챗봇은 이용하기 어렵죠.

20
00:05:20,100 --> 00:05:30,000
GPU로 돌리면 얼마나 걸리나 궁금했습니다.

21
00:05:30,100 --> 00:05:40,000
하지만 GPU가 없어서 테스트를 못했습니다.

22
00:05:40,100 --> 00:05:50,000
그래서 이 구글 코랩의 GPU를 이용합니다.

23
00:05:50,100 --> 00:06:00,000
1달 이용료가 $9.9 입니다.

24
00:06:00,100 --> 00:06:10,000
많이 쓰면 그 전에 소진됩니다.

25
00:06:10,100 --> 00:06:20,000
라마3은 하루만에도 $9.9를 모두 소진 시킵니다.

26
00:06:20,100 --> 00:06:30,000
A100 GPU의 그래픽 카드는 2,000만원 정도 입니다.

27
00:06:30,100 --> 00:06:40,000
오픈AI의 챗GPT는 H100 GPU로 가동됩니다.

28
00:06:40,100 --> 00:06:50,000
H100 수십만개를 구매해서 병렬처리 합니다.

29
00:06:50,000 --> 00:07:00,000
1개에 5,000만원이 넘습니다.

30
00:07:00,100 --> 00:07:10,000
메타는 H100 수십만 개를 구매했습니다.

31
00:07:10,100 --> 00:07:20,000
엔비디아에게서 H100을 서로 구입하려고 경쟁합니다.

32
00:07:20,100 --> 00:07:30,000
네이버는 H100 1,000개로 하이퍼클로버를 운영합니다.

33
00:07:30,100 --> 00:07:40,000
공단은 H100은 커녕 A100 1개도 없습니다.

34
00:07:40,100 --> 00:07:50,000
GPU 1개로 LLM 운영은 어렵습니다.

35
00:07:50,100 --> 00:08:00,000
PCIe 슬롯 여러개가 있는 서버가 필요합니다.

36
00:08:00,100 --> 00:08:10,000
그래픽카드 여러개로 병렬 처리 되어야 합니다.

37
00:08:10,100 --> 00:13:00,000
그래야 챗봇이 답변을 10초 내에 합니다.



38
00:13:00,100 --> 00:13:20,000
챗봇 UI가 나오기 시작했습니다.

39
00:13:20,100 --> 00:14:05,000
로딩이 많이 진행되었습니다.

40
00:14:05,100 --> 00:14:30,000
로딩이 완료되었습니다.

41
00:14:30,100 --> 00:14:50,000
이제 챗봇에게 질문할 수 있습니다.










1
00:00:00,000 --> 00:00:03,000
청크구분 변경: 380자 => 질문~ 단위

2
00:00:03,100 --> 00:00:10,000
고객상담 pdf 파일을 등록합니다.

3
00:00:10,100 --> 00:00:27,000
학습 파일이 처리되고 있습니다.

4
00:00:27,100 --> 00:00:40,000
상시근로자가 월 중에 부득이하게 퇴사한 경우, 어디로 신고하죠?

5
00:00:40,100 --> 00:00:50,000
검색된 청크와 질문을 라마3 LLM에게 전달합니다.

6
00:00:50,100 --> 00:01:00,000
라마3은 청크를 참조해서 답변을 생성합니다.

7
00:01:00,100 --> 00:03:15,000
2분 30초 걸립니다.







8
00:03:15,100 --> 00:03:20,000
답변이 생성되었습니다.

9
00:03:20,100 --> 00:03:40,000
pdf의 질문 세트를 정확하게 반영했습니다.

10
00:03:40,100 --> 00:03:47,000
올바른 답변을 간결하게 생성했습니다.








