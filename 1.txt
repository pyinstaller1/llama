0
검색해서 구글 코랩에 들어갑니다.

15
A100 GPU를 선택합니다.


23
구글 코랩에 연결되고 있습니다.


30
연결 목적은 GPU 이용입니다.

40
사무실에 GPU가 없으니까요.


50
파이썬 코드, 학습 자료 업로드

1:30
RAG 라이브러리 설치

2:20
ngrok 연결 준비


2:30
ngrok 으로 코랩에서 챗봇 UI를 띄웁니다.

2:55
ngrok 으로 챗봇 URL을 얻습니다.

3:10
챗봇을 시작합니다.

4:00
먼저 라마3 LLM을 VRAM에 로드합니다.

4:10
10분 정도 소요됩니다.

4:20
로딩이 끝나면 챗봇을 이용할 수 있습니다.



계속 기다려야 합니다.

지루하시면 12:55 로 건너뛰기 하세요.


GPU가 없어서 구글 코랩을 이용합니다.

사무실 PC의 CPU로는 8시간 만에 답변합니다.

8시간 만에 답변 하는 챗봇은 이용하기 어렵죠.


GPU로 돌리면 얼마나 걸리나 궁금했습니다.

하지만 GPU가 없어서 테스트를 못했습니다.

그래서 이 구글 코랩의 GPU를 이용합니다.

1달 이용료가 $9.9 입니다.

많이 쓰면 그 전에 소진됩니다.

라마3은 하루만에도 $9.9를 모두 소진 시킵니다.

A100 GPU의 그래픽 카드는 2,000만원 정도 입니다.

오픈AI의 챗GPT는 H100 GPU로 가동됩니다.

H100 수십만개를 구매해서 병렬처리 합니다.

1개에 5,000만원이 넘습니다.

메타는 H100 수십만 개를 구매했습니다.

엔비디아에게서 H100을 서로 구입하려고 경쟁합니다.

네이버는 H100 1,000개로 하이퍼클로버를 운영합니다.

공단은 H100은 커녕 A100 1개도 없습니다.

GPU 1개로 LLM 운영은 어렵습니다.

PCIe 슬롯 여러개가 있는 서버가 필요합니다.

그래픽카드 여러개가 병렬 처리 되어야 합니다.































13:00
챗봇 UI가 나오기 시작했습니다.

13:20
로딩이 많이 진행되었습니다.

14:05
로딩이 완료되었습니다.


14:30
이것은 챗봇의 파이썬 코드입니다.

14:50
이제 챗봇에게 질문할 수 있습니다.



































